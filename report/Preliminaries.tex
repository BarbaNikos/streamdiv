\section{Preliminaries}
Both diversity and relevance have been explored to quite some depth within the broader context of \textit{representative data exploration} techniques. The diversity of a set of tuples is usually defined using a distance measure between pairs of tuples. In the case of numerical attributes, this could be the Euclidean distance between the data points, whereas in other cases, this could be a function specific to the type of data we are dealing with. Formally, let $d(t_i,t_j)$ denote the distance between two tuples $t_i$ and $t_j$. One possible measure of diversity of a set $S$ is the sum of pairwise distance of all the points in $S$ and is defined as
\begin{equation}div(S) = \sum_{i=1}^{|S|}\sum_{j>i}^{|S|}d(t_i,t_j)\end{equation}
The objective of diversification algorithms is the pick a subset $S*$ with a fixed size $k$ from a larger set $D$ such that the diversity of set $S*$ is maximum. In other words
\begin{equation}S^{*}=\underset{S\subseteq D, |S|=k}{argmax} div(S)\end{equation}
Such an optimization problem has been shown to be NP hard. Several heuristics, however, have been proposed in the research literature that aim to achieve diversity close to the optimal.
While diversity in general is not query specific, the relevance of a set $S$ is usually based on the similarity of the tuples in $S$ to the user query posed to the database. Again, for numerical attributes, this similarity could be the proximity of a tuple to a desired, possibly non-existent, tuple or point in the sample space as per the user query. The overall relevance of the set $S$ is usually defined as the sum of the individual relevance scores of the points within the set. 
Techniques to extract representative data that is most diverse and also contains relevant results usually employ the MMR, or the Maximum Marginal Relevance, scheme, in which the objective function is the weighted sum of the diversity and relevance score of the subset. As both diversity and relevance are orthogonal, and sometimes conflicting, objectives, the weights in these schemes are usually pre specified based on problem requirements and properties of the dataset.

Most of the literature focuses on the problem of diversification and relevancy in the framework of traditional databases, where the data is stored on a disk and all of the data is available to the representative data extraction algorithm as it looks through the entire haystack to pick out a small \textit{representative} subset. The luxury of looking at the entire dataset is not afforded in a streaming system where the system only sees incoming windows of tuples and has to process them on the fly. The incoming data is not stored in its entirety because, at high input rates, the amount of data would quickly exceed the storage capacity. Even if the system has enough storage space to store all the data that it receives, the timing requirements in the streaming system are quite strict. The algorithm would be required to produce the top k attributes at fixed intervals and looking at the entire dataset may take enough time that the system fails to meet its deadline. In this work we look at the problem of diversification and relevance maximization in the context of streaming databases and develop schemes that would work in an online setting, producing high quality results at fixed intervals or as soon as new tuples arrive in the system.

Another aspect that becomes more prominent in streaming systems is the recency of the tuples produced. There may be applications that would prefer to see more recent results at the expense of diversity and/or relevance. One reason for this could be to observe trends in user tweets, for example in the case of twitter data. Our schemes also include the recency of tuples as an objective. We also explore the tradeoff between all these three objectives and their impact on the quality of results produced. 